{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb3e178",
   "metadata": {},
   "source": [
    "# PyBADS Example 1: Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191949",
   "metadata": {},
   "source": [
    "In this introductory example, we will show a simple usage of Bayesian Adaptive Direct Search (BADS) to perform optimization of a synthetic target function.\n",
    "\n",
    "This notebook is Part 1 of a series of notebooks in which we present various example usages for BADS with the PyBADS package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef2e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pybads.bads.bads import BADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7fc85",
   "metadata": {},
   "source": [
    "## 0. What is (Py)BADS?\n",
    "\n",
    "BADS is a fast hybrid Bayesian optimization algorithm designed to solve difficult optimization problems, in particular related to parameter estimation -- aka model fitting -- of computational models (e.g., via maximum-likelihood or maximum-a-posteriori estimation). **PyBADS is its Python implementation**.\n",
    "\n",
    "BADS has been intensively tested for fitting a variety of computational models, and is currently used by many research groups around the world (see [Google Scholar](https://scholar.google.co.uk/scholar?cites=7209174494000095753&as_sdt=2005&sciodt=0,5&hl=en) for many example applications). In our benchmark with real model-fitting problems, BADS performed on par or better than many other common and state-of-the-art optimizers, as shown in the [original BADS paper](https://arxiv.org/abs/1705.04405).\n",
    "\n",
    "BADS is recommended when no gradient information is available, and the objective function is non-analytical or noisy, for example evaluated through numerical approximation or via simulation.\n",
    "It requires no specific tuning and runs off-the-shelf like other built-in optimizers (e.g., from `scipy.optimize.minimize`).\n",
    "\n",
    "*Note*: If you are interested in estimating posterior distributions (i.e., uncertainty and error bars) over model parameters, and not just point estimates, you might also want to check out Variational Bayesian Monte Carlo for Python (PyVBMC), a package for Bayesian posterior and model inference which can be used in synergy with PyBADS.\n",
    "\n",
    "### Optimization problem\n",
    "\n",
    "Formally, the goal of BADS is to *minimize* a target (or objective) function $f(\\mathbf{x}): \\mathbb{R}^D \\rightarrow \\mathbb{R}$, for $\\mathbf{x} \\in \\mathbb{R}^D$,\n",
    "$$\n",
    "\\mathbf{x}^\\star = \\arg\\min_\\mathbf{x} f(\\mathbf{x}) \\qquad \\text{with} \\; \\text{lb}_d \\le x_d \\le \\text{ub}_d \\; \\text{ for } 1\\le d \\le D,\n",
    "$$\n",
    "where $D$ is the dimensionality of the problem and `lb`, `ub` are arrays representing lower/upper bound constraints, which can be set to infinite for unbounded parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456c17e",
   "metadata": {},
   "source": [
    "## 1. Problem setup\n",
    "\n",
    "Here we show PyBADS at work on [Rosenbrock's banana function](https://en.wikipedia.org/wiki/Rosenbrock_function) in 2D as target function.  \n",
    "\n",
    "We specify wide hard bounds and tighter plausible bounds that (hopefully) contain the solution. \n",
    "- Hard lower/upper bounds `lb`, `ub` are the actual optimization bounds; PyBADS will not evaluate the target function outside these bounds, but might evaluate the target on the bounds. You can use `-np.inf` and `np.inf` for unbounded parameters.\n",
    "- Plausible lower/upper bounds `plb`, `pub` represent our best guess at bounding the region where the solution might lie. The plausible bounds do not change the optimization problem, but help define the initial exploration and hyperparameters of PyBADS.\n",
    "\n",
    "We set as starting point for the optimization $\\mathbf{x}_0 = (0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d439732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrocks_fcn(x):\n",
    "    \"\"\"Rosenbrock's 'banana' function in any dimension.\"\"\"\n",
    "    x_2d = np.atleast_2d(x)\n",
    "    return np.sum(100 * (x_2d[:, 0:-1]**2 - x_2d[:, 1:])**2 + (x_2d[:, 0:-1]-1)**2, axis=1)\n",
    "\n",
    "target = rosenbrocks_fcn;\n",
    "\n",
    "lb = np.array([[-20, -20]])     # Lower bounds\n",
    "ub = np.array([[20, 20]])       # Upper bounds\n",
    "plb = np.array([[-5, -5]])      # Plausible lower bounds\n",
    "pub = np.array([[5, 5]])        # Plausible upper bounds\n",
    "x0 = np.array([[0, 0]]);        # Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb12aa",
   "metadata": {},
   "source": [
    "## 2. Initialize and run the optimization\n",
    "\n",
    "Then, we initialize a `bads` instance which takes care of the optimization. For now, we use default options.  \n",
    "To run the optimization, we simply call `bads.optimize()`, which returns an `OptimizeResult` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8863184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning optimization of a DETERMINISTIC objective function\n",
      "\n",
      " Iteration f-count     f(x)     MeshScale     Method     Actions\n",
      "     0         2       1.000000      1.000000            Uncertainty test\n",
      "     0        18       1.000000      1.000000     Initial mesh       Initial points\n",
      "     0        22       1.000000      0.500000     Refine grid       Train\n",
      "     1        25       0.050902      0.500000     Successful search (('ES-wcm', 1))       \n",
      "     1        34       0.050902      0.250000     Refine grid       Train\n",
      "     2        35       0.028340      0.250000     Incremental search (('ES-ell', 1))       \n",
      "     2        36       0.013988      0.250000     Incremental search (('ES-ell', 1))       \n",
      "     2        42       0.013988      0.125000     Refine grid       Train\n",
      "     3        44       0.005871      0.125000     Incremental search (('ES-ell', 1))       \n",
      "     3        50       0.005871      0.062500     Refine grid       \n",
      "     4        51       0.005400      0.062500     Incremental search (('ES-ell', 1))       \n",
      "     4        58       0.005400      0.031250     Refine grid       \n",
      "     5        60       0.000196      0.031250     Incremental search (('ES-ell', 1))       \n",
      "     5        66       0.000196      0.015625     Refine grid       Train\n",
      "     6        67       0.000031      0.015625     Incremental search (('ES-ell', 1))       \n",
      "     6        74       0.000031      0.007812     Refine grid       Train\n",
      "     7        77       0.000023      0.007812     Incremental search (('ES-ell', 1))       \n",
      "     7        82       0.000023      0.003906     Refine grid       \n",
      "     8        86       0.000003      0.003906     Incremental search (('ES-ell', 1))       \n",
      "     8        90       0.000003      0.000977     Refine grid       \n",
      "     9        92       0.000003      0.000977     Incremental search (('ES-ell', 1))       \n",
      "     9        98       0.000003      0.000244     Refine grid       Train\n",
      "    10        99       0.000001      0.000244     Incremental search (('ES-wcm', 1))       \n",
      "Optimization terminated: change in the function value less than options.TolFun.\n",
      "Function value at minimum: 1.4832317043623423e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bads = BADS(target, x0, lb, ub, plb, pub)\n",
    "optimize_result = bads.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc75241",
   "metadata": {},
   "source": [
    "## 3. Results and conclusions\n",
    "\n",
    "We examine now the result of the optimization stored in `optimize_result`. The most important keys are the minimum, `optimize_result['x']`, and the value of the function at the solution, `optimize_result['fval']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b95d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BADS minimum at: x_min = [1.0011892  1.00235354], fval = 1.483e-06\n",
      "total f-count: 99, time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "x_min = optimize_result['x']\n",
    "fval = optimize_result['fval']\n",
    "\n",
    "print(f\"BADS minimum at: x_min = {x_min.flatten()}, fval = {fval:.4g}\")\n",
    "print(f\"total f-count: {optimize_result['func_count']}, time: {round(optimize_result['total_time'], 2)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d79d83",
   "metadata": {},
   "source": [
    "The true minimum of the Rosenbrock function is at $\\textbf{x}^\\star = [1, 1]$, where $f^\\star = 0$.  \n",
    "\n",
    "In conclusion, PyBADS found the solution with a fairly small number of function evaluations (`f-count`), which is particularly important if the target function is mildly-to-very expensive to compute as in many computational models.\n",
    "\n",
    "*Note*: PyBADS by default does not aim for extreme numerical precision of the target (e.g., beyond the 2nd or 3rd decimal place), since in most realistic model-fitting problems a higher resolution is typically pointless, e.g. due to noise or variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8571e",
   "metadata": {},
   "source": [
    "## Example 1: Full code\n",
    "\n",
    "See [here](./src/pybads_example_1_basic_usage.py) for a Python file with the code used in this example, with no extra fluff."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
