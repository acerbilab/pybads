{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb3e178",
   "metadata": {},
   "source": [
    "# PyBADS Example 1: Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191949",
   "metadata": {},
   "source": [
    "In this introductory example, we will show a simple usage of Bayesian Adaptive Direct Search (BADS) to perform optimization of a synthetic target function.\n",
    "\n",
    "This notebook is Part 1 of a series of notebooks in which we present various example usages for BADS with the PyBADS package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef2e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pybads.bads.bads import BADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7fc85",
   "metadata": {},
   "source": [
    "## 0. What is (Py)BADS?\n",
    "\n",
    "BADS is a fast hybrid Bayesian optimization algorithm designed to solve difficult optimization problems, in particular related to parameter estimation -- aka model fitting -- of computational models (e.g., via maximum-likelihood or maximum-a-posteriori estimation). **PyBADS is its Python implementation**.\n",
    "\n",
    "BADS has been intensively tested for fitting a variety of computational models, and is currently used by many research groups around the world (see [Google Scholar](https://scholar.google.co.uk/scholar?cites=7209174494000095753&as_sdt=2005&sciodt=0,5&hl=en) for many example applications). In our benchmark with real model-fitting problems, BADS performed on par or better than many other common and state-of-the-art optimizers, as shown in the [original BADS paper](https://arxiv.org/abs/1705.04405).\n",
    "\n",
    "BADS is recommended when no gradient information is available, and the objective function is non-analytical or noisy, for example evaluated through numerical approximation or via simulation.\n",
    "It requires no specific tuning and runs off-the-shelf like other built-in optimizers (e.g., from `scipy.optimize.minimize`).\n",
    "\n",
    "*Note*: If you are interested in estimating posterior distributions (i.e., uncertainty and error bars) over model parameters, and not just point estimates, you might also want to check out Variational Bayesian Monte Carlo for Python (PyVBMC), a package for Bayesian posterior and model inference which can be used in synergy with PyBADS.\n",
    "\n",
    "### Optimization problem\n",
    "\n",
    "Formally, the goal of BADS is to *minimize* a target (or objective) function $f(\\mathbf{x}): \\mathbb{R}^D \\rightarrow \\mathbb{R}$, for $\\mathbf{x} \\in \\mathbb{R}^D$,\n",
    "$$\n",
    "\\mathbf{x}^\\star = \\arg\\min_\\mathbf{x} f(\\mathbf{x}) \\qquad \\text{with} \\; \\text{lb}_d \\le x_d \\le \\text{ub}_d \\; \\text{ for } 1\\le d \\le D,\n",
    "$$\n",
    "where $D$ is the dimensionality of the problem and `lb`, `ub` are arrays representing lower/upper bound constraints, which can be set to infinite for unbounded parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456c17e",
   "metadata": {},
   "source": [
    "## 1. Problem setup\n",
    "\n",
    "Here we show PyBADS at work on [Rosenbrock's banana function](https://en.wikipedia.org/wiki/Rosenbrock_function) in 2D as target function.  \n",
    "\n",
    "We specify wide hard bounds and tighter plausible bounds that (hopefully) contain the solution. \n",
    "- Hard lower/upper bounds `lb`, `ub` are the actual optimization bounds; PyBADS will not evaluate the target function outside these bounds, but might evaluate the target on the bounds. You can use `-np.inf` and `np.inf` for unbounded parameters.\n",
    "- Plausible lower/upper bounds `plb`, `pub` represent our best guess at bounding the region where the solution might lie. The plausible bounds do not change the optimization problem, but help define the initial exploration and hyperparameters of PyBADS.\n",
    "\n",
    "We set as starting point for the optimization $\\mathbf{x}_0 = (0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d439732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosenbrocks_fcn(x):\n",
    "    \"\"\"Rosenbrock's 'banana' function in any dimension.\"\"\"\n",
    "    x_2d = np.atleast_2d(x)\n",
    "    return np.sum(100 * (x_2d[:, 0:-1]**2 - x_2d[:, 1:])**2 + (x_2d[:, 0:-1]-1)**2, axis=1)\n",
    "\n",
    "target = rosenbrocks_fcn;\n",
    "\n",
    "lb = np.array([[-20, -20]])     # Lower bounds\n",
    "ub = np.array([[20, 20]])       # Upper bounds\n",
    "plb = np.array([[-5, -5]])      # Plausible lower bounds\n",
    "pub = np.array([[5, 5]])        # Plausible upper bounds\n",
    "x0 = np.array([[0, 0]]);        # Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb12aa",
   "metadata": {},
   "source": [
    "## 2. Initialize and run the optimization\n",
    "\n",
    "Then, we initialize a `bads` instance which takes care of the optimization. For now, we use default options.  \n",
    "To run the optimization, we simply call `bads.optimize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8863184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables (index) defined with periodic boundaries: []\n",
      "Beginning optimization of a DETERMINISTIC objective function\n",
      "\n",
      " Iteration f-count     f(x)     MeshScale     Method     Actions\n",
      "     0         3       1.000000      1.000000            Uncertainty test\n",
      "     0         7       1.000000      1.000000     Initial mesh       Initial points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luigi\\documents\\github\\gpyreg\\gpyreg\\covariance_functions.py:376: RuntimeWarning: invalid value encountered in add\n",
      "  plausible_lower_bounds[i_nan] + plausible_upper_bounds[i_nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0        11       1.000000      0.500000     Refine grid       Train\n",
      "     1        19       1.000000      0.250000     Refine grid       Train\n",
      "     2        20       0.196665      0.250000     Successful search (('ES-wcm', 1))       \n",
      "     2        25       0.000392      0.250000     Successful search (('ES-wcm', 1))       \n",
      "     2        30       0.000053      0.250000     Incremental search (('ES-ell', 1))       \n",
      "     2        35       0.000053      0.125000     Refine grid       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luigi\\documents\\github\\pybads\\pybads\\bads\\bads.py:1760: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  zscore = zscore / gp_ys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3        43       0.000053      0.062500     Refine grid       Train\n",
      "     4        51       0.000053      0.031250     Refine grid       Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\luigi\\documents\\github\\pybads\\pybads\\bads\\bads.py:1555: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  gamma_z = (self.optim_state['f_target'] - self.sufficient_improvement - f_mu) / fs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "     5        54       0.000042      0.031250     Incremental search (('ES-ell', 1))       \n",
      "bads: The optimization is stalling, decreasing further the mesh size\n",
      "     5        59       0.000042      0.007812     Refine grid       \n",
      "     6        61       0.000036      0.007812     Incremental search (('ES-ell', 1))       \n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "bads: The optimization is stalling, decreasing further the mesh size\n",
      "     6        67       0.000036      0.001953     Refine grid       Train\n",
      "     7        68       0.000034      0.001953     Incremental search (('ES-ell', 1))       \n",
      "Optimization terminated: change in the function value less than options.TolFun.\n",
      "Function value at minimum: 3.425035546065382e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bads = BADS(target, x0, lb, ub, plb, pub)\n",
    "x_min, fval = bads.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc75241",
   "metadata": {},
   "source": [
    "## 3. Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b95d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BADS minimum at: x_min = [0.99522173 0.99012839], fval = 3.425e-05\n",
      "total f-count: 67, time: 4.34 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"BADS minimum at: x_min = {x_min.flatten()}, fval = {fval:.4g}\")\n",
    "print(f\"total f-count: {bads.function_logger.func_count-1}, time: {round(bads.optim_state['total_time'], 2)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d79d83",
   "metadata": {},
   "source": [
    "The true minimum of the Rosenbrock function is at $\\textbf{x}^\\star = [1, 1]$, where $f^\\star = 0$.  \n",
    "\n",
    "In conclusion, PyBADS found the solution with a fairly small number of function evaluations (`f-count`), which is particularly important if the target function is mildly-to-very expensive to compute as in many computational models.\n",
    "\n",
    "*Note*: PyBADS by default does not aim for extreme numerical precision of the target (e.g., beyond the 2nd or 3rd decimal place), since in most realistic model-fitting problems a higher resolution is typically pointless, e.g. due to noise or variability in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8571e",
   "metadata": {},
   "source": [
    "## Example 1: Full code\n",
    "\n",
    "See [here](./src/pybads_example_1_basic_usage.py) for a Python file with the code used in this example, with no extra fluff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d0f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
