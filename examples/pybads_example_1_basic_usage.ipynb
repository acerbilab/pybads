{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeb3e178",
   "metadata": {},
   "source": [
    "# PyBADS Example 1: Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f191949",
   "metadata": {},
   "source": [
    "In this introductory example, we will show a simple usage of Bayesian Adaptive Direct Search (BADS) to perform optimization of a synthetic target function.\n",
    "\n",
    "This notebook is Part 1 of a series of notebooks in which we present various example usages for BADS with the PyBADS package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef2e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import FALSE\n",
    "import numpy as np\n",
    "from pybads.bads.bads import BADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7fc85",
   "metadata": {},
   "source": [
    "## 0. What is (Py)BADS?\n",
    "\n",
    "BADS is a fast Bayesian optimization algorithm designed to solve difficult optimization problems, in particular related to parameter estimation -- aka model fitting -- of computational models (e.g., via maximum-likelihood or maximum-a-posteriori estimation). **PyBADS is its Python implementation**.\n",
    "\n",
    "BADS has been intensively tested for fitting a variety of computational models, and is currently used by many research groups around the world (see [Google Scholar](https://scholar.google.co.uk/scholar?cites=7209174494000095753&as_sdt=2005&sciodt=0,5&hl=en) for many example applications). In our benchmark with real model-fitting problems, BADS performed on par or better than many other common and state-of-the-art optimizers, as shown in the [original BADS paper](https://arxiv.org/abs/1705.04405).\n",
    "\n",
    "BADS is recommended when no gradient information is available, and the objective function is non-analytical or noisy, for example evaluated through numerical approximation or via simulation.\n",
    "It requires no specific tuning and runs off-the-shelf like other built-in optimizers (e.g., from `scipy.optimize`).\n",
    "\n",
    "*Note*: If you are interested in estimating posterior distributions (i.e., uncertainty and error bars) over model parameters, and not just point estimates, you might also want to check out Variational Bayesian Monte Carlo for Python (PyVBMC), a package for Bayesian posterior and model inference which can be used in synergy with PyBADS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2456c17e",
   "metadata": {},
   "source": [
    "## 1. Problem definition\n",
    "\n",
    "Here we show PyBADS at work on [Rosenbrock's banana function](https://en.wikipedia.org/wiki/Rosenbrock_function) in 2D as target function.\n",
    "\n",
    "We specify wide hard bounds and tighter plausible bounds that (hopefully) contain the solution. \n",
    "- Hard lower/upper bounds `lb`, `ub` are the actual optimization bounds; PyBADS will not evaluate the target function outside these bounds, but might evaluate them on the bounds.\n",
    "- Plausible lower/upper bounds `plb`, `pub` represent our best guess at bounding the region where the solution might lie. The plausible bounds do not change the optimization problem, but help define starting points and hyperparameters of PyBADS.\n",
    "\n",
    "We set a starting point for the optimization $\\mathbf{x}_0 = (0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d439732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybads.function_examples import rosenbrocks_fcn\n",
    "target = rosenbrocks_fcn;\n",
    "\n",
    "lb = np.array([[-20, -20]])     # Lower bounds\n",
    "ub = np.array([[20, 20]])       # Upper bounds\n",
    "plb = np.array([[-5, -5]])      # Plausible lower bounds\n",
    "pub = np.array([[5, 5]])        # Plausible upper bounds\n",
    "x0 = np.array([[0, 0]]);        # Starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb12aa",
   "metadata": {},
   "source": [
    "## 2. Initialize and run the optimization\n",
    "\n",
    "Then, we initialize a `bads` instance which takes care of the optimization. For now, we use default options.  \n",
    "To run the optimization, we simply call `bads.optimize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8863184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables (index) defined with periodic boundaries: []\n",
      "Beginning optimization of a DETERMINISTIC objective function\n",
      "\n",
      " Iteration f-count     f(x)     MeshScale     Method     Actions\n",
      "     0         3       1.000000      1.000000            Uncertainty test\n",
      "     0         7       1.000000      1.000000     Initial mesh       Initial points\n",
      "     0        11       1.000000      0.500000     Refine grid       Train\n",
      "     1        19       1.000000      0.250000     Refine grid       Train\n",
      "     2        21       0.532334      0.250000     Successful search (('ES-ell', 1))       \n",
      "     2        22       0.205350      0.250000     Successful search (('ES-ell', 1))       \n",
      "     2        23       0.031554      0.250000     Successful search (('ES-ell', 1))       \n",
      "     2        25       0.000405      0.250000     Incremental search (('ES-ell', 1))       \n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "     2        31       0.000405      0.125000     Refine grid       Train\n",
      "     3        39       0.000405      0.062500     Refine grid       Train\n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "     4        42       0.000038      0.062500     Incremental search (('ES-ell', 1))       \n",
      "     4        47       0.000038      0.031250     Refine grid       \n",
      "bads: The optimization is stalling, decreasing further the mesh size\n",
      "     5        55       0.000038      0.007812     Refine grid       Train\n",
      "bads:_robust_gp_fit_: posterior GP update failed. Singular matrix for L Cholesky decomposition\n",
      "bads: The optimization is stalling, decreasing further the mesh size\n",
      "     6        63       0.000038      0.001953     Refine grid       Train\n",
      "     7        64       0.000020      0.001953     Incremental search (('ES-wcm', 1))       \n",
      "Optimization terminated: change in the function value less than options.TolFun.\n",
      "Function value at minimum: 2.0356943038612996e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bads = BADS(target, x0, lb, ub, plb, pub)\n",
    "x_min, fval = bads.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b95d46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BADS minimum at: x = [1.00111511 1.00266865], fval = 2.036e-05\n",
      "total f-count: 64, time: 4.28 s\n"
     ]
    }
   ],
   "source": [
    "print(f\"BADS minimum at: x = {x_min.flatten()}, fval = {fval:.4g}\")\n",
    "print(f\"total f-count: {bads.function_logger.func_count}, time: {round(bads.optim_state['total_time'], 2)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d79d83",
   "metadata": {},
   "source": [
    "The true minimum is at $\\textbf{x}^\\star = [1, 1]$, where $f_\\text{min} = 0$.  \n",
    "\n",
    "In conclusion, PyBADS found the solution with a very small number of function evaluations (`f-count`), which is particularly important if the target function is mildly-to-very expensive to compute as in many computational models.\n",
    "\n",
    "*Note*: PyBADS by default does not aim for extreme numerical precision of the target (e.g., beyond the 2nd or 3rd decimal place), since in most realistic model-fitting problems a higher resolution is typically pointless, e.g. due to noise or variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60d5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
