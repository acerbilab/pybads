{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48db32f",
   "metadata": {},
   "source": [
    "# PyBADS Example 5: Extended usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b5d8b",
   "metadata": {},
   "source": [
    "In this example, we will show PyBADS at work on a multimodal target and showcase some additional features.\n",
    "\n",
    "This notebook is Part 5 of a series of notebooks in which we present various example usages for BADS with the PyBADS package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c7306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pybads.bads.bads import BADS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd1931",
   "metadata": {},
   "source": [
    "## 1. Problem setup\n",
    "\n",
    "In this example, we are going to optimize the *six-hump camelback function*, which has six local minima, two of which are global minima.\n",
    "\n",
    "Note that, in most realistic scenarios, you would not know whether your problem has only a single local minimum (which is also the global minimum). In practice, many optimization problems exhibit *multiple* local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192fbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camelback6(x):\n",
    "    \"\"\"Six-hump camelback function.\"\"\"\n",
    "    x_2d = np.atleast_2d(x)\n",
    "    x1 = x_2d[:,0]\n",
    "    x2 = x_2d[:,1]\n",
    "    f = (4 - 2.1*(x1*x1) + (x1*x1*x1*x1)/3.0)*(x1*x1) + x1*x2 + (-4 + 4*(x2*x2))*(x2*x2)\n",
    "    return f\n",
    "\n",
    "lb = np.array([-3, -2])       # Lower bounds\n",
    "ub = np.array([3, 2])         # Upper bounds\n",
    "plb = np.array([-2.9, -1.9])  # Plausible lower bounds\n",
    "pub = np.array([2.9, 1.9])    # Plausible upper bounds\n",
    "\n",
    "options = {\n",
    "    \"display\" : 'off',             # We switch off the printing\n",
    "    \"uncertainty_handling\": False, # Good to specify that this is a deterministic function\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e280e",
   "metadata": {},
   "source": [
    "## 2. Run the optimization\n",
    "\n",
    "PyBADS is not a global optimization algorithm in that there is no guarantee that a single run would return the global optimum (in fact, this is true of almost all algorithms). The gold rule of optimization, regardless of optimization algorithm, is to always rerun the optimization multiple times from different starting points (a multi-start strategy), to explore the landscape of the target and gain some confidence about the results.\n",
    "\n",
    "Below, we rerun PyBADS `num_opts` times from different starting points and store the results of each run, which we will examine later. Note that we switched off PyBADS default printing.\n",
    "\n",
    "Also note that each optimization uses a different `BADS` object (the general rule is: one BADS instance per optimization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853bf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running optimization 0...\n",
      "Function value at minimum: -1.0316188687309946\n",
      "\n",
      "Running optimization 1...\n",
      "Function value at minimum: -1.031627209412116\n",
      "\n",
      "Running optimization 2...\n",
      "Function value at minimum: -1.031624709878634\n",
      "\n",
      "Running optimization 3...\n",
      "Function value at minimum: -1.0316266405918255\n",
      "\n",
      "Running optimization 4...\n",
      "Function value at minimum: -1.031628154388721\n",
      "\n",
      "Running optimization 5...\n",
      "Function value at minimum: -1.031627526801249\n",
      "\n",
      "Running optimization 6...\n",
      "Function value at minimum: -1.0316222000749877\n",
      "\n",
      "Running optimization 7...\n",
      "Function value at minimum: -1.0316274584136575\n",
      "\n",
      "Running optimization 8...\n",
      "Function value at minimum: -1.0316266950914683\n",
      "\n",
      "Running optimization 9...\n",
      "Function value at minimum: -1.031598130313844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_opts = 10\n",
    "optimize_results = []\n",
    "x_vec = np.zeros((num_opts,lb.shape[0]))\n",
    "fval_vec = np.zeros(num_opts)\n",
    "\n",
    "for opt_count in range(num_opts):\n",
    "    print('Running optimization ' + str(opt_count) + '...')\n",
    "    x0 = np.random.uniform(low=plb, high=pub)\n",
    "    bads = BADS(camelback6, x0, lb, ub, plb, pub, options=options)\n",
    "    optimize_results.append(bads.optimize())\n",
    "    x_vec[opt_count] = optimize_results[opt_count].x\n",
    "    fval_vec[opt_count] = optimize_results[opt_count].fval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7af7d8",
   "metadata": {},
   "source": [
    "## 3. Results and conclusions\n",
    "\n",
    "First, we inspect the results. In this example, the target function has two equally-good solutions, \n",
    "$$\n",
    "x^\\star = \\left\\{ (0.0898, -0.7126), (-0.0898, 0.7126) \\right\\}, \\qquad f(x^\\star) = -1.0316\n",
    "$$\n",
    "which should be represented in the set of results. \n",
    "\n",
    "Importantly, we should find below that (almost) all solutions are very close in function value, suggesting that we found the minimizers of the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7af9c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found solutions:\n",
      "[[-0.09141472  0.71270269]\n",
      " [ 0.09040388 -0.7127438 ]\n",
      " [-0.08887769  0.712464  ]\n",
      " [ 0.09051437 -0.71260872]\n",
      " [-0.08956575  0.71261778]\n",
      " [-0.08951874  0.71238403]\n",
      " [ 0.0903595  -0.71348572]\n",
      " [ 0.09020462 -0.71243477]\n",
      " [-0.09045906  0.71250725]\n",
      " [ 0.08708241 -0.71281016]]\n",
      "Function values at solutions:\n",
      "[-1.03161887 -1.03162721 -1.03162471 -1.03162664 -1.03162815 -1.03162753\n",
      " -1.0316222  -1.03162746 -1.0316267  -1.03159813]\n"
     ]
    }
   ],
   "source": [
    "print('Found solutions:')\n",
    "print(x_vec)\n",
    "\n",
    "print('Function values at solutions:')\n",
    "print(fval_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834d1d4",
   "metadata": {},
   "source": [
    "We now take the best result of the optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6507b31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BADS minimum at x_min = [-0.08956575  0.71261778]\n",
      "Function value at minimum fval = -1.031628154388721\n"
     ]
    }
   ],
   "source": [
    "idx_best = np.argmin(fval_vec)\n",
    "result_best = optimize_results[idx_best]\n",
    "\n",
    "x_min = result_best['x']\n",
    "fval = result_best['fval']\n",
    "\n",
    "print(f\"BADS minimum at x_min = {x_min.flatten()}\")\n",
    "print(f\"Function value at minimum fval = {fval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ace561",
   "metadata": {},
   "source": [
    "The best result indeed matches $f^\\star = -1.0316$.\n",
    "\n",
    "The `OptimizeResult` object returned by PyBADS contains further information about the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eebe659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fun': <function __main__.camelback6(x)>,\n",
       " 'non_box_cons': None,\n",
       " 'target_type': 'deterministic',\n",
       " 'problem_type': 'bound constraints',\n",
       " 'iterations': 8,\n",
       " 'func_count': 85,\n",
       " 'mesh_size': 0.0009765625,\n",
       " 'overhead': 18951355.422884997,\n",
       " 'algorithm': 'Bayesian adaptive direct search',\n",
       " 'yval_vec': None,\n",
       " 'ysd_vec': None,\n",
       " 'x0': array([[ 0.68893913, -1.51155983]]),\n",
       " 'x': array([-0.08956575,  0.71261778]),\n",
       " 'fval': -1.031628154388721,\n",
       " 'fsd': 0,\n",
       " 'total_time': 1.591913939522339,\n",
       " 'success': True,\n",
       " 'random_seed': None,\n",
       " 'version': '0.0.1',\n",
       " 'message': 'Optimization terminated: change in the function value less than options.TolFun.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83320a21",
   "metadata": {},
   "source": [
    "## Example 5: Full code\n",
    "\n",
    "See [here](./src/pybads_example_5_extended_usage.py) for a Python file with the code used in this example, with no extra fluff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb6d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
